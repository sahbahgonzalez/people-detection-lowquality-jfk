{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8-p3rtc3MxBC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "410087c8-a7bd-4d73-9175-a16d92898060"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'A' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2685308504.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m vintage_transform = A.Compose([\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Slight random resize & crop (simulates film jitter / framing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomResizedCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
          ]
        }
      ],
      "source": [
        "# Task 3- cell 1\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # upload eval_ground_truth_counts.csv\n",
        "gt_csv_path = list(uploaded.keys())[0]\n",
        "print(\"Uploaded ground-truth file:\", gt_csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cell 2\n",
        "# Upload a zip file containing your frames (JPG/PNG)\n",
        "uploaded = files.upload()  # choose e.g. JFK_4_frames.zip\n",
        "\n",
        "zip_name = list(uploaded.keys())[0]\n",
        "print(\"Uploaded:\", zip_name)\n",
        "\n",
        "# Unzip into /content/frames\n",
        "os.makedirs(\"frames\", exist_ok=True)\n",
        "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"frames\")\n",
        "\n",
        "image_paths = sorted(glob(\"frames/**/*.*\", recursive=True))\n",
        "print(f\"Found {len(image_paths)} images\")\n",
        "image_paths[:5]\n"
      ],
      "metadata": {
        "id": "KNYpfgbC5Lwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3 - cell 3\n",
        "import os, shutil, numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# Use the newly unzipped frames as source\n",
        "all_frames = sorted(\n",
        "    glob(\"frames/**/*.jpg\", recursive=True) +\n",
        "    glob(\"frames/**/*.png\", recursive=True)\n",
        ")\n",
        "\n",
        "print(\"Total frames found in frames/:\", len(all_frames))\n",
        "\n",
        "num_eval = 50\n",
        "indices = np.linspace(0, len(all_frames) - 1, num_eval, dtype=int)\n",
        "eval_frames = [all_frames[i] for i in indices]\n",
        "\n",
        "os.makedirs(\"eval_frames\", exist_ok=True)\n",
        "\n",
        "for p in eval_frames:\n",
        "    shutil.copy(p, \"eval_frames/\" + os.path.basename(p))\n",
        "\n",
        "print(\"Saved 50 evaluation frames to /content/eval_frames\")\n"
      ],
      "metadata": {
        "id": "dhD9qYYa6SNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 4\n",
        "!pip install ultralytics albumentations opencv-python-headless matplotlib tqdm --quiet\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from glob import glob\n",
        "import json\n",
        "import shutil\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "vxhJ70Cm6Uq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 5\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "id": "NafsfK3e6Xro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 6\n",
        "model = YOLO(\"/content/drive/MyDrive/crowdhuman_models/best.pt\")\n",
        "print(\"Loaded fine-tuned model.\")\n"
      ],
      "metadata": {
        "id": "UFB9P7EG6aMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 7\n",
        "def yolo_heatmap_on_image(img_bgr, model, conf_thresh=0.15, sigma=25):\n",
        "    \"\"\"\n",
        "    img_bgr: OpenCV BGR image\n",
        "    model: YOLO model\n",
        "    conf_thresh: minimum confidence for keeping a detection\n",
        "    sigma: Gaussian blur strength for heatmap\n",
        "    \"\"\"\n",
        "    h, w = img_bgr.shape[:2]\n",
        "\n",
        "    # Run YOLO\n",
        "    results = model.predict(\n",
        "        source=img_bgr,\n",
        "        conf=conf_thresh,\n",
        "        verbose=False\n",
        "    )[0]\n",
        "\n",
        "    # Count persons + create point map\n",
        "    point_map = np.zeros((h, w), dtype=np.float32)\n",
        "    person_count = 0\n",
        "\n",
        "    for box in results.boxes:\n",
        "        cls = int(box.cls[0])\n",
        "        conf = float(box.conf[0])\n",
        "        if cls != 0 or conf < conf_thresh:  # class 0 = person\n",
        "            continue\n",
        "\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "        cx = int((x1 + x2) / 2)\n",
        "        cy = int((y1 + y2) / 2)\n",
        "\n",
        "        if 0 <= cx < w and 0 <= cy < h:\n",
        "            point_map[cy, cx] += 1.0\n",
        "            person_count += 1\n",
        "\n",
        "    # Turn point map into smooth heatmap\n",
        "    heatmap = cv2.GaussianBlur(point_map, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
        "\n",
        "    # Normalize heatmap to [0, 255]\n",
        "    heatmap_norm = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    heatmap_norm = heatmap_norm.astype(np.uint8)\n",
        "\n",
        "    # Colorize\n",
        "    heatmap_color = cv2.applyColorMap(heatmap_norm, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Overlay onto original frame\n",
        "    overlay = cv2.addWeighted(img_bgr, 0.6, heatmap_color, 0.4, 0)\n",
        "\n",
        "    # Get YOLO's built-in annotated image (boxes, labels)\n",
        "    annotated = results.plot()  # returns BGR image\n",
        "\n",
        "    return annotated, overlay, person_count\n"
      ],
      "metadata": {
        "id": "JstLS83c6c1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 8\n",
        "pred_counts = {}  # recreate it from scratch\n",
        "\n",
        "image_paths = sorted(glob(\"eval_frames/*.jpg\") + glob(\"eval_frames/*.png\"))\n",
        "\n",
        "for img_path in image_paths:\n",
        "    img_name = os.path.basename(img_path)\n",
        "    img_bgr = cv2.imread(img_path)\n",
        "\n",
        "    annotated, overlay, person_count = yolo_heatmap_on_image(\n",
        "        img_bgr,\n",
        "        model,\n",
        "        conf_thresh=0.15,\n",
        "        sigma=25\n",
        "    )\n",
        "\n",
        "    pred_counts[img_name] = person_count\n",
        "    print(f\"{img_name}: predicted {person_count} people\")\n"
      ],
      "metadata": {
        "id": "pkPDUHQy6e-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 9\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Load ground-truth counts\n",
        "gt_counts = {}\n",
        "with open(gt_csv_path, \"r\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        gt_counts[row[\"frame\"]] = int(row[\"true_count\"])\n",
        "\n",
        "# Compute per-frame absolute errors on frames that appear in both\n",
        "errors = []\n",
        "for name, true_c in gt_counts.items():\n",
        "    if name in pred_counts:\n",
        "        err = abs(true_c - pred_counts[name])\n",
        "        errors.append(err)\n",
        "        print(f\"{name}: true={true_c}, pred={pred_counts[name]}, |err|={err}\")\n",
        "\n",
        "mae = float(np.mean(errors)) if errors else None\n",
        "print(\"\\nNumber of eval frames used:\", len(errors))\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n"
      ],
      "metadata": {
        "id": "FlUo5LTX6hkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}