{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4npXDzPF7JSN"
      },
      "outputs": [],
      "source": [
        "#Task 4 - cell 1\n",
        "from google.colab import files\n",
        "import zipfile, os, glob\n",
        "\n",
        "# Upload labels_my-project-name_....zip from your Downloads\n",
        "uploaded = files.upload()\n",
        "zip_name = list(uploaded.keys())[0]\n",
        "print(\"Uploaded:\", zip_name)\n",
        "\n",
        "# Extract into gt_yolo/\n",
        "os.makedirs(\"gt_yolo\", exist_ok=True)\n",
        "with zipfile.ZipFile(zip_name, \"r\") as z:\n",
        "    z.extractall(\"gt_yolo\")\n",
        "\n",
        "# Find images inside the extracted folder\n",
        "img_exts = (\"*.jpg\", \"*.jpeg\", \"*.png\")\n",
        "image_paths = []\n",
        "for ext in img_exts:\n",
        "    image_paths.extend(glob.glob(os.path.join(\"gt_yolo\", \"**\", ext), recursive=True))\n",
        "\n",
        "print(\"Found images:\", len(image_paths))\n",
        "image_paths[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cell 2\n",
        "def load_gt_boxes_yolo(image_paths, root_dir=\"gt_yolo\"):\n",
        "    \"\"\"\n",
        "    Returns dict:\n",
        "      gt_boxes[img_path] = list of [x1, y1, x2, y2] (absolute pixel coords)\n",
        "    \"\"\"\n",
        "    gt_boxes = {}\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        txt_path = os.path.join(os.path.dirname(img_path), base + \".txt\")\n",
        "\n",
        "        if not os.path.exists(txt_path):\n",
        "            # no labels for this frame -> skip\n",
        "            continue\n",
        "\n",
        "        boxes = []\n",
        "        with open(txt_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) != 5:\n",
        "                    continue\n",
        "                cls_id, xc, yc, bw, bh = map(float, parts)\n",
        "                # Only keep class 0 = person\n",
        "                if int(cls_id) != 0:\n",
        "                    continue\n",
        "\n",
        "                # YOLO normalized -> absolute xyxy\n",
        "                x_center = xc * w\n",
        "                y_center = yc * h\n",
        "                box_w = bw * w\n",
        "                box_h = bh * h\n",
        "\n",
        "                x1 = x_center - box_w / 2\n",
        "                y1 = y_center - box_h / 2\n",
        "                x2 = x_center + box_w / 2\n",
        "                y2 = y_center + box_h / 2\n",
        "\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "\n",
        "        if boxes:\n",
        "            gt_boxes[img_path] = np.array(boxes, dtype=np.float32)\n",
        "\n",
        "    return gt_boxes\n",
        "\n",
        "gt_boxes = load_gt_boxes_yolo(image_paths)\n",
        "print(\"Images with GT boxes:\", len(gt_boxes))\n",
        "list(gt_boxes.keys())[:5]\n"
      ],
      "metadata": {
        "id": "4eOH3fNH7Qg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cell 3\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# --- Helper: IoU between two boxes (x1,y1,x2,y2) ---\n",
        "def iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    interW = max(0, xB - xA)\n",
        "    interH = max(0, yB - yA)\n",
        "    interArea = interW * interH\n",
        "\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "\n",
        "    boxAArea = max(0, boxA[2] - boxA[0]) * max(0, boxA[3] - boxA[1])\n",
        "    boxBArea = max(0, boxB[2] - boxB[0]) * max(0, boxB[3] - boxB[1])\n",
        "\n",
        "    return interArea / float(boxAArea + boxBArea - interArea + 1e-9)\n",
        "\n",
        "# --- Run YOLO on each GT image and collect stats ---\n",
        "conf_thresh = 0.25   # same-ish as before\n",
        "iou_thresh  = 0.5    # standard mAP/PR IoU threshold\n",
        "\n",
        "TP = FP = FN = 0\n",
        "per_image_stats = []\n",
        "\n",
        "for img_path, boxes_gt in gt_boxes.items():\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(\"Could not read:\", img_path)\n",
        "        continue\n",
        "\n",
        "    # YOLO inference\n",
        "    results = model.predict(source=img, conf=conf_thresh, verbose=False)[0]\n",
        "\n",
        "    # collect person detections (class 0)\n",
        "    preds = []\n",
        "    for b in results.boxes:\n",
        "        if int(b.cls[0]) != 0:\n",
        "            continue  # only 'person'\n",
        "        x1, y1, x2, y2 = b.xyxy[0].cpu().numpy().tolist()\n",
        "        preds.append([x1, y1, x2, y2])\n",
        "\n",
        "    preds = np.array(preds, dtype=np.float32) if len(preds) > 0 else np.zeros((0,4), dtype=np.float32)\n",
        "    gts   = boxes_gt.astype(np.float32)\n",
        "\n",
        "    matched_gt = set()\n",
        "    matched_pr = set()\n",
        "\n",
        "    # greedy matching: for each prediction, match to best GT if IoU >= thresh\n",
        "    for pi, p_box in enumerate(preds):\n",
        "        best_iou = 0.0\n",
        "        best_gi  = -1\n",
        "        for gi, g_box in enumerate(gts):\n",
        "            if gi in matched_gt:\n",
        "                continue\n",
        "            i = iou(p_box, g_box)\n",
        "            if i > best_iou:\n",
        "                best_iou = i\n",
        "                best_gi  = gi\n",
        "        if best_iou >= iou_thresh and best_gi >= 0:\n",
        "            matched_pr.add(pi)\n",
        "            matched_gt.add(best_gi)\n",
        "\n",
        "    tp_i = len(matched_pr)\n",
        "    fp_i = len(preds) - tp_i\n",
        "    fn_i = len(gts) - tp_i\n",
        "\n",
        "    TP += tp_i\n",
        "    FP += fp_i\n",
        "    FN += fn_i\n",
        "\n",
        "    per_image_stats.append((\n",
        "        os.path.basename(img_path),\n",
        "        tp_i, fp_i, fn_i,\n",
        "        len(preds), len(gts)\n",
        "    ))\n",
        "\n",
        "# --- Print per-image stats ---\n",
        "print(\"Per-image stats (name, TP, FP, FN, #preds, #GT):\\n\")\n",
        "for name, tp_i, fp_i, fn_i, n_pred, n_gt in per_image_stats:\n",
        "    print(f\"{name}: TP={tp_i}, FP={fp_i}, FN={fn_i}, preds={n_pred}, GT={n_gt}\")\n",
        "\n",
        "# --- Global metrics ---\n",
        "precision = TP / (TP + FP + 1e-9) if (TP + FP) > 0 else 0.0\n",
        "recall    = TP / (TP + FN + 1e-9) if (TP + FN) > 0 else 0.0\n",
        "f1        = 2 * precision * recall / (precision + recall + 1e-9) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "print(\"\\n==== Global detection metrics (IoU >= 0.5, class=person) ====\")\n",
        "print(f\"TP: {TP}, FP: {FP}, FN: {FN}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall:    {recall:.3f}\")\n",
        "print(f\"F1-score:  {f1:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LmQVmNsj7T8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}